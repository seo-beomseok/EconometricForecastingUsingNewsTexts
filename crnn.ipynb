{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ellwQNucYzw7",
   "metadata": {
    "id": "ellwQNucYzw7"
   },
   "source": [
    "This script contains the CRNN codes for Seo,B.(2024), 'Econometric Forecasting Using Ubiquitous News Texts: Text-enhanced Factor Model' International Journal of Forecasting\n",
    "\n",
    "-Last Update: 2024-11-24 <br>\n",
    "-Author: Beomseok Seo (bsseo@sookmyung.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FzHWT3aWY93E",
   "metadata": {
    "id": "FzHWT3aWY93E"
   },
   "source": [
    "### 0. <font color=purple> Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d0ff2c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2615,
     "status": "ok",
     "timestamp": 1732455388549,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "d7d0ff2c"
   },
   "outputs": [],
   "source": [
    "import os, copy, pickle\n",
    "from os import walk\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5445159d",
   "metadata": {
    "executionInfo": {
     "elapsed": 10064,
     "status": "ok",
     "timestamp": 1732455398611,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "5445159d"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b16ff6ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 5515,
     "status": "ok",
     "timestamp": 1732455404124,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "b16ff6ef"
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels as sm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ythNTdJUZJX-",
   "metadata": {
    "executionInfo": {
     "elapsed": 8319,
     "status": "ok",
     "timestamp": 1732455480975,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "ythNTdJUZJX-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fcddf1b",
   "metadata": {
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1732455433897,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "4fcddf1b"
   },
   "outputs": [],
   "source": [
    "# To display pandas in full dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0765742f",
   "metadata": {
    "id": "0765742f"
   },
   "outputs": [],
   "source": [
    "# Set criteria\n",
    "def rmse(y_pred,y_true):\n",
    "    return np.sqrt(np.mean((y_pred-y_true)**2))\n",
    "def mae(y_pred,y_true):\n",
    "    return np.mean(np.abs(y_pred-y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab425a2d",
   "metadata": {},
   "source": [
    "### 1. <font color='purple'>Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2748160",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = '240101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3def12",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = pd.read_csv('./data/all_dat_YoY.csv', index_col=0)\n",
    "all_grp = pd.read_csv('./data/all_grp.csv', index_col=0)\n",
    "macro_feat = pd.read_csv('./data/macro_feat.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31d95063",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat.index = pd.PeriodIndex(all_dat.index, freq='M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "609f26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grp_eng = copy.deepcopy(all_grp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19579014",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grp_eng_index = \\\n",
    "['GDP(SA)(Q)','GDP(NSA)(Q)',\n",
    " 'Private consumption(SA)(Q)', 'Government consumption(SA)(Q)', 'Construction(SA)(Q)', 'Facility investment(SA)(Q)',\n",
    " 'Exports of goods and services(SA)(Q)', 'Imports of goods and services(SA)(Q)',\n",
    " 'Private consumption(NSA)(Q)', 'Government consumption(NSA)(Q)', 'Construction(NSA)(Q)', 'Facility investment(NSA)(Q)',\n",
    " 'Exports of goods and services(NSA)(Q)', 'Imports of goods and services(NSA)(Q)',\n",
    " 'Unemployment rate', 'Employment to population ratio', 'Number of employed people',\n",
    " 'Monthly goods exports','Monthly goods imports',\n",
    " 'Export price index','Import price index','Producer price index','Consumer price index',\n",
    " 'Price index excluding agricultural product & oil', 'Price index excluding food & energy',\n",
    " 'Consumption & Retail sales index(SA)','Service industry production index(SA)',\n",
    " 'Consumption & Retail sales index(NSA)','Service industry production index(NSA)',\n",
    " 'Manufacturing industry production index(SA)', 'Manufacturing industry shipment index(SA)', 'Manufacturing inventory index(SA)',\n",
    " 'Manufacturing industry production index(NSA)', 'Manufacturing industry shipment index(NSA)', 'Manufacturing inventory index(NSA)',\n",
    " 'Facility investment index(SA)','Construction completed(SA)',\n",
    " 'Facility investment index(NSA)','Construction completed(NSA)',\n",
    " 'Manufacturing business performance BSI(SA)','Manufacturing business performance BSI(NSA)',\n",
    " 'All industries performance BSI', 'Service industry performance BSI', 'All industries sales BSI',\n",
    " 'Manufacturing export BSI', 'Manufacturing domestic demand sales BSI', 'Manufacturing new orders BSI', 'Manufacturing operation rate BSI',\n",
    " 'Economic sentiment index', 'Current economic judgment CSI', 'Consumer sentiment index',\n",
    " 'Consolidated fiscal balance',\n",
    " 'Housing sales price index(HSPI)-Seoul', 'Housing sales price index(HSPI)-National', 'Housing lease price index(HLPI)-Seoul', 'Housing lease price index(HLPI)-National',\n",
    " 'Call rate','CD rate','KTB 3-year rate','KRW exchange rate', 'EUR exchange rate', 'KOSPI', 'KOSDAQ', \n",
    " 'Dubai crude oil', 'WTI futures', 'Gold futures',\n",
    " 'Production(T)','Shipbuilding(T)','Automotive(T)','Semiconductor(T)','Facility investment(T)','Construction(T)',\n",
    " 'Unemployment(T)','Recruitment(T)','Job search(T)',\n",
    " 'Wholesale & retail(T)', 'Government expenditure(T)','Price outlook(T)','Stock price outlook(T)','House price outlook(T)',\n",
    " 'World trade(T)',\n",
    " 'News sentiment index(T)','Economic policy uncertainty(T)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1b41b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grp_eng.columns = ['External','Production','Labor','Consumption','Facility Inv.','Construction','Government','Exports','Imports','Prices','Finance','Real estate','Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93ed9a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat_eng = copy.deepcopy(all_dat)\n",
    "all_dat_eng.columns = all_grp_eng_index\n",
    "all_grp_eng.index = all_grp_eng_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3e955e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dat = all_dat_eng\n",
    "all_grp = all_grp_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Z_McilR6ZmpK",
   "metadata": {
    "id": "Z_McilR6ZmpK"
   },
   "source": [
    "### 2. <font color='purple'>Generate vintage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "PiFUxezMZkXv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 1545,
     "status": "error",
     "timestamp": 1732455602880,
     "user": {
      "displayName": "Beomseok Seo",
      "userId": "04799372747311841122"
     },
     "user_tz": -540
    },
    "id": "PiFUxezMZkXv",
    "outputId": "0f87964b-f0c1-4794-c3dc-73e1d0bc0420"
   },
   "outputs": [],
   "source": [
    "macro_lag = macro_feat['LAG'].values\n",
    "finan_lag = np.zeros(14)\n",
    "text_lag = np.zeros(17)\n",
    "\n",
    "all_lag = np.concatenate([macro_lag,finan_lag,text_lag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3gUZvY_SZtBj",
   "metadata": {
    "id": "3gUZvY_SZtBj"
   },
   "outputs": [],
   "source": [
    "test_dates = [str(x) for x in all_dat.index if str(x)>='2016-01' and int(str(x)[-2:])%3==0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "oUejQQhkZqWb",
   "metadata": {
    "id": "oUejQQhkZqWb"
   },
   "outputs": [],
   "source": [
    "def _GenVintage(all_dat):\n",
    "    vintage_dict = dict()\n",
    "    for i in test_dates:\n",
    "        temp_dat = copy.deepcopy(all_dat)\n",
    "        temp_dat = temp_dat.loc[:i]\n",
    "\n",
    "        for j,l in enumerate(all_lag):\n",
    "            if l==0:\n",
    "                continue\n",
    "            temp_dat.iloc[-int(l):,j] = np.nan\n",
    "\n",
    "        vintage_dict[i] = temp_dat\n",
    "\n",
    "    return vintage_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "uQf-WJHHZvKB",
   "metadata": {
    "id": "uQf-WJHHZvKB"
   },
   "outputs": [],
   "source": [
    "vintage_dict = _GenVintage(all_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4806f055",
   "metadata": {},
   "source": [
    "### 3. <font color='purple'>Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad1a9b",
   "metadata": {},
   "source": [
    "#### convolutional recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aaeda8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "factornames = {1:'External',2:'Production',3:'Labor',4:'Consumption',5:'Facility Inv.',6:'Construction',7:'Government',8:'Exports',9:'Imports',10:'Prices',11:'Finance',12:'Real estate',13:'Sentiments'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20c28128",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_multiplicities = {'Global': 2}\n",
    "factor_orders = {'Global': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6048826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = dict()\n",
    "results_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ed81257",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_dict_keys = ['2016-03', '2016-06', '2016-09', '2016-12', '2017-03', '2017-06', '2017-09', '2017-12', '2018-03', '2018-06', '2018-09', '2018-12', '2019-03', '2019-06', '2019-09', '2019-12', '2020-03', '2020-06', '2020-09', '2020-12', '2021-03', '2021-06', '2021-09', '2021-12', '2022-03', '2022-06', '2022-09', '2022-12', '2023-03', '2023-06', '2023-09']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b5409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6384851c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for fhor in ['now','1qa']:\n",
    "    for trans in ['MoM','OS_MoM','NE_MoM','YoY','OS_YoY','NE_YoY']:\n",
    "\n",
    "        all_dat_P = copy.deepcopy(all_dat)\n",
    "        all_grp_P = copy.deepcopy(all_grp)\n",
    "\n",
    "        if trans[:2] == 'NE':\n",
    "            for i,x in enumerate(all_dat_P.columns):\n",
    "                if x[-3:] != '(T)' and i>=14:\n",
    "                    all_dat_P.drop(x,axis=1, inplace=True)\n",
    "                    all_grp_P.drop(x,axis=0, inplace=True)\n",
    "\n",
    "        if trans[:2] == 'OS':\n",
    "            for i,x in enumerate(all_dat_P.columns):\n",
    "                if x[-3:] == '(T)':\n",
    "                    all_dat_P.drop(x,axis=1, inplace=True)\n",
    "                    all_grp_P.drop(x,axis=0, inplace=True)  \n",
    "\n",
    "        vitage_dict = _GenVintage(all_dat_P)\n",
    "        \n",
    "        \n",
    "        pred_crnn = []\n",
    "        err_crnn = []\n",
    "        true_crnn = []\n",
    "        #==========================================================================================\n",
    "        for v in vintage_dict_keys:\n",
    "            vintage_dat = vintage_dict[v]\n",
    "\n",
    "            if trans[-3:] in ['YoY']:\n",
    "                item = 'GDP(NSA)(Q)'\n",
    "            elif trans[-3:] in ['MoM']:\n",
    "                item = 'GDP(SA)(Q)'\n",
    "\n",
    "            if fhor == 'now':\n",
    "                vd_train_x_m = vintage_dat.iloc[12:-3,14:].fillna(method='ffill').fillna(method='bfill')\n",
    "                vd_train_x_q = vintage_dat.iloc[9:-6,:14].dropna()\n",
    "                vd_train_y_q = vintage_dat.iloc[12:-3,:14][item].dropna()\n",
    "\n",
    "                testing_x_m = np.expand_dims(vintage_dat.iloc[-36:,14:].fillna(method='ffill'),(0,3))\n",
    "                testing_x_q = np.expand_dims(vintage_dat.iloc[-39:-3,:14].dropna(),0)\n",
    "                testing_y_q = np.expand_dims(all_dat.loc[str(vintage_dat.iloc[[-1],:].index[0]), item],0)\n",
    "            elif fhor == '1qa':\n",
    "                vd_train_x_m = vintage_dat.iloc[9:-6,14:].fillna(method='ffill').fillna(method='bfill')\n",
    "                vd_train_x_q = vintage_dat.iloc[6:-9,:14].dropna()\n",
    "                vd_train_y_q = vintage_dat.iloc[12:-3,:14][item].dropna()\n",
    "\n",
    "                testing_x_m = np.expand_dims(vintage_dat.iloc[-39:-3,14:].fillna(method='ffill'),(0,3))\n",
    "                testing_x_q = np.expand_dims(vintage_dat.iloc[-42:-6,:14].dropna(),0)\n",
    "                testing_y_q = np.expand_dims(all_dat.loc[str(vintage_dat.iloc[[-1],:].index[0]), item],0)\n",
    "\n",
    "            ds_train_x_m = tf.keras.utils.timeseries_dataset_from_array(vd_train_x_m, targets=None, sequence_length=36, sequence_stride=3)\n",
    "            ds_train_x_q = tf.keras.utils.timeseries_dataset_from_array(vd_train_x_q, None, sequence_length=12, sequence_stride=1)\n",
    "            ds_train_y_q = tf.keras.utils.timeseries_dataset_from_array(vd_train_y_q, None, sequence_length=1, sequence_stride=1, start_index=11)\n",
    "\n",
    "\n",
    "            train_x_m = np.transpose(np.stack(list(ds_train_x_m)),(1,2,3,0))\n",
    "            train_x_q = np.squeeze(np.transpose(np.stack(list(ds_train_x_q)),(1,2,3,0)))\n",
    "            train_y_q = np.squeeze(np.stack(list(ds_train_y_q)))\n",
    "\n",
    "            print(np.sum(np.isnan(train_x_m)),np.sum(np.isnan(train_x_q)),np.sum(np.isnan(train_y_q)))\n",
    "            print(train_x_m.shape, train_x_q.shape, train_y_q.shape)\n",
    "\n",
    "            tf_train_x_mq = tf.data.Dataset.from_tensor_slices((train_x_m,train_x_q))\n",
    "            tf_train_y_q = tf.data.Dataset.from_tensor_slices(train_y_q)\n",
    "\n",
    "            train_ds = tf.data.Dataset.zip((tf_train_x_mq, tf_train_y_q)).batch(32).repeat()\n",
    "\n",
    "            tf_testing_x_mq = tf.data.Dataset.from_tensor_slices((testing_x_m,testing_x_q))\n",
    "            tf_testing_y_q = tf.data.Dataset.from_tensor_slices(testing_y_q)\n",
    "\n",
    "            testing_ds = tf.data.Dataset.zip((tf_testing_x_mq, tf_testing_y_q)).batch(32).repeat()\n",
    "\n",
    "\n",
    "            #---------------------------------------------------------------------------------------------------\n",
    "            inp_m = tf.keras.layers.Input(shape=train_x_m.shape[1:])\n",
    "            inp_q = tf.keras.layers.Input(shape=train_x_q.shape[1:])\n",
    "            #---------------------------------------------------------------------------------------------------\n",
    "            xm = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,vd_train_x_m.shape[1]), strides=3, activation='relu', use_bias=True)(inp_m)\n",
    "            xm = tf.keras.layers.Lambda(lambda x: x[:, :, 0, :])(xm)\n",
    "            xmq = tf.keras.layers.Lambda(lambda x: tf.concat(x,axis=-1))([xm,inp_q])\n",
    "            xx = tf.keras.layers.LSTM(32)(xmq)\n",
    "            xx = tf.keras.layers.Dense(4, activation='relu', use_bias=True)(xx)\n",
    "            out = tf.keras.layers.Dense(1, activation='linear', use_bias=True)(xx)\n",
    "            \n",
    "            #---------------------------------------------------------------------------------------------------\n",
    "            model_lin = tf.keras.models.Model([inp_m,inp_q],out)\n",
    "            #---------------------------------------------------------------------------------------------------\n",
    "\n",
    "            EVALUATION_INTERVAL = 500\n",
    "            EPOCHS = 5\n",
    "\n",
    "            model_lin.compile(loss=tf.losses.MeanAbsoluteError(),\n",
    "                        optimizer=tf.optimizers.Adam(learning_rate = 0.002),\n",
    "                        metrics=[tf.metrics.MeanSquaredError()])\n",
    "\n",
    "            history = model_lin.fit(train_ds,\n",
    "                                steps_per_epoch=EVALUATION_INTERVAL,\n",
    "                                epochs=EPOCHS)#, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "            Path(\"./outs/crnn_out_{}_{}\".format(trans,fhor)).mkdir(parents=True, exist_ok=True)\n",
    "            model_lin.save('./outs/crnn_out_{}_{}/crnn_{}.keras'.format(trans,fhor,v))\n",
    "\n",
    "            pred_nc = model_lin.predict((testing_x_m,testing_x_q))[0][0]\n",
    "\n",
    "            pred_crnn.append(pred_nc)\n",
    "            err_crnn.append(testing_y_q[0]-pred_nc)\n",
    "            true_crnn.append(testing_y_q[0])\n",
    "            print(v, 'pred:',pred_nc, 'true:',testing_y_q[0], 'err:',testing_y_q[0]-pred_nc)\n",
    "\n",
    "        crnn_ = pd.DataFrame({'index':vintage_dict_keys, 'true':true_crnn, 'pred':pred_crnn,'err':err_crnn})\n",
    "        crnn_.set_index('index', inplace=True)\n",
    "\n",
    "#         Path(\"./outs/collect\").mkdir(parents=True, exist_ok=True)\n",
    "#         crnn_.to_csv('./outs/collect/crnn_{}_{}.csv'.format(trans,fhor))\n",
    "#         print(fhor, trans, np.mean(np.abs(crnn_['err'])))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ab425a2d",
    "scwyZtSUrYKD",
    "baad1a9b"
   ],
   "gpuClass": "premium",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
